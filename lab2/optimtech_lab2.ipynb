{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPY165cDDJTz"
   },
   "source": [
    "# Lab. 2: Stochastic global optimization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### <u>The goal of this laboratory is to study the application of stochastic global search algorithms on different benchmark functions.</u>\n",
    "\n",
    "We will study two methods:\n",
    "- *DIRECT*\n",
    "- *Basin-hopping*\n",
    "\n",
    "Moreover, we will study the effect of their parameters on the outcome of the search.\n",
    "\n",
    "---\n",
    "\n",
    "Getting started: the following code cell contains the core functions that we will use. Hence, **remember to run it every time the runtime is reconnected**.\n",
    "\n",
    "You can find a wrapper function for the  two algorithm, together with a wrapper for the benchmark function.\n",
    "As regards the *OptFun* class, the constructor takes as input a benchmark function (we will see later what functions are available). The relevant methods  are 4:\n",
    "1.   *Minima*: return the minimum of the function. The position can be obtained by the parameter *position* and the function value from the *score* parameter.\n",
    "2.   *Bounds*: returns where the function is defined\n",
    "3.   *Heatmap*: show a heatmap of the function highlighting the points visited by the local search (use with 2d function)\n",
    "4.   *plot*: show the trend of the points visited by the local search (use with 1d function)\n",
    "5.   *trend*: show the best points find during the optmization process.\n",
    "\n",
    "Each instance of *OptFun* stores the history of the point at which the function has been evaluated. The history is never cleaned and can be obtained through *OptFun.history*. Hence, if you reuse the class instance remember to clean the history (*OptFun.history = list()*).\n",
    "\n",
    "---\n",
    "\n",
    "The benchmark functions available comes from the *benchmark_functions* library (imported as *bf*).\n",
    "Example of the functions that can be used are the *Hypersphere*, the *Rastrign* the *DeJong5* and the Keane.\n",
    "The complete list of functions available can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions) or you can print it with *dir(bf)*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Czm90e6dDNxa"
   },
   "source": [
    "#### Base code to run every time the runtime is reconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1709841654724,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "k9t_QSgtDGjU"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipydirect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbenchmark_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipydirect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize \u001b[38;5;28;01mas\u001b[39;00m spdirect\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# colab env\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipydirect'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m   get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall scipydirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbenchmark_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbf\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipydirect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize \u001b[38;5;28;01mas\u001b[39;00m spdirect\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipydirect'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "try:\n",
    "  import benchmark_functions as bfp\n",
    "  from scipydirect import minimize as spdirect\n",
    "except:  # colab env\n",
    "  %pip install benchmark_functions\n",
    "  %pip install scipydirect\n",
    "  import benchmark_functions as bf\n",
    "  from scipydirect import minimize as spdirect\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import basinhopping as spbasinhopping\n",
    "import inspect\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "3hAGFGMlDQcY"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 154\u001b[0m\n\u001b[0;32m    148\u001b[0m     best_position \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mhistory[history\u001b[38;5;241m.\u001b[39mindex(best_score)]\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, best_position, best_score\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbasinhopping\u001b[39m(\n\u001b[0;32m    153\u001b[0m     f: OptFun,\n\u001b[1;32m--> 154\u001b[0m     x0: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    155\u001b[0m     T: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    156\u001b[0m     stepsize: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m    157\u001b[0m     stepsize_interval: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m    158\u001b[0m     maxiter: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Optimizes a function by using the Basin-hopping algorithm.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    - maxiter: maximum number of iterations\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spbasinhopping(\n\u001b[0;32m    170\u001b[0m         f,\n\u001b[0;32m    171\u001b[0m         x0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    183\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "class OptFun():\n",
    "    def __init__(self, wf):\n",
    "        self.f = wf\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, x0):\n",
    "        self.history.append(deepcopy(x0))\n",
    "        return self.f(x0)\n",
    "\n",
    "    def minima(self):\n",
    "        \"\"\"\n",
    "        Returns a list of Optimum objects of the known global minima. If there aren't any minima, an empty list value will be returned instead;\n",
    "\n",
    "        Returns:\n",
    "        - List of objects of class \"benchmark_functions.functions_info_loader.Optimum\"\n",
    "        - For each object:\n",
    "          - Access to 'position' parameter to get the axis values\n",
    "          - Access to 'score' parameter to get the value of the function\n",
    "        \"\"\"\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounds(self):\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, fn = None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        fig.canvas.manager.set_window_title('Benchmark Function: '+self.f._name)\n",
    "        fig.suptitle(self.f._name)\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        if self.f._n_dimensions>1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray([[self.f((X[i][j],Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x,y,Z,15,linewidths=0.5,colors='k') # hight lines\n",
    "        plt.contourf(x,y,Z,15,cmap='viridis', vmin=Z.min(), vmax=Z.max()) # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history)>0:\t# plot points\n",
    "            xdata = [x[0] for x in self.history]\n",
    "            xdata = xdata[1:]\n",
    "            ydata = [x[1] for x in self.history]\n",
    "            ydata = ydata[1:]\n",
    "\n",
    "            plt.plot(xdata, ydata, \"or-\", markersize=5, linewidth=1.5)\n",
    "            plt.plot(xdata[0], ydata[0], marker='X', markersize=13, color='black')\n",
    "\n",
    "            plt.plot(xdata[-1], ydata[-1], marker='P', markersize=13,color='white')\n",
    "            # TODO\n",
    "            # - bigger markersize for initial and final point + diff color\n",
    "            # - check f vs func\n",
    "            # - check num iter vs how many points are being plotted\n",
    "        if fn is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(fn, dpi=400)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        values = values[1:]\n",
    "        min = func.minima()[0].score\n",
    "\n",
    "        plt.plot(values, label=\"Scores\",marker='o')\n",
    "\n",
    "        plt.axhline(min, color=\"r\", label=\"optimum\", linestyle='dashed')\n",
    "        plt.xlabel('Iterations/Evaluations')  # TODO\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(self, bounds):\n",
    "        new_bounds= []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self):\n",
    "        return len(self.history)\n",
    "\n",
    "def grid_search(f: OptFun, step_size=None, number_of_steps=None, minimization=True):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the grid_search algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - step_size: the step size\n",
    "    - number_of_steps: the total number of steps\n",
    "    - minimization: boolean, True if looking for minimum, False if looking for maximum; defauls True\n",
    "\n",
    "    Returns:\n",
    "    - best value found\n",
    "    \"\"\"\n",
    "\n",
    "    if (step_size != None):\n",
    "      range_step_size = step_size\n",
    "    elif (number_of_steps != None):\n",
    "        range_step_size = int(np.floor(np.sqrt(number_of_steps)))\n",
    "    else:\n",
    "        print(\"Please provide at least the step_size or the number_of_steps\")\n",
    "        return\n",
    "\n",
    "    bounds = f.bounds()\n",
    "    best = float('inf') if minimization else float('sup')\n",
    "\n",
    "    for x in np.arange(bounds[0][0], bounds[0][1], range_step_size):\n",
    "      for y in np.arange(bounds[1][0], bounds[1][1], range_step_size):\n",
    "        current = f([x, y])\n",
    "        if minimization:\n",
    "          if current < best:\n",
    "            best = current\n",
    "        else:\n",
    "          if current > best:\n",
    "            best = current\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def direct(f: OptFun, eps: float = 1e-4, maxiter: int = 1000, maxfneval: int = 1000, optima: int = None, error_tollerance: int = None):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the DIRECT algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - eps: regulates the trade-off between local and global exploration.\n",
    "            The smaller the eps, the finer the granularity of the search.\n",
    "    - maxiter: maximum number of iterations\n",
    "    -\n",
    "    \"\"\"\n",
    "    bounds = f.bounds()\n",
    "    results =  spdirect(\n",
    "        func,\n",
    "        bounds=bounds,\n",
    "        eps=eps,\n",
    "        maxT=maxiter,\n",
    "        maxf=maxfneval,\n",
    "        fglobal=-1e100,\n",
    "        fglper=0.001,\n",
    "        volper=-1.0,\n",
    "        sigmaper=-1.0\n",
    "    )\n",
    "    history = [func.f(v) for v in func.history]\n",
    "    history = history[1:]\n",
    "    best_score = min(history)\n",
    "    best_position = func.history[history.index(best_score)]\n",
    "    return results, best_position, best_score\n",
    "\n",
    "\n",
    "def basinhopping(\n",
    "    f: OptFun,\n",
    "    x0: np.ndarray,\n",
    "    T: float = 1.0,\n",
    "    stepsize: float = 0.5,\n",
    "    stepsize_interval: int = 50,\n",
    "    maxiter: int = 1000):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the Basin-hopping algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - x0: starting point for the search process\n",
    "    - T: temperature parameter\n",
    "    - stepsize: maximum step size for random displacement\n",
    "    - stepsize_interval: interval for the update of the step size\n",
    "    - maxiter: maximum number of iterations\n",
    "    \"\"\"\n",
    "    return spbasinhopping(\n",
    "        f,\n",
    "        x0,\n",
    "        niter=maxiter,\n",
    "        T=T,\n",
    "        stepsize=stepsize,\n",
    "        minimizer_kwargs=None,\n",
    "        take_step=None,\n",
    "        accept_test=None,\n",
    "        callback=None,\n",
    "        interval=stepsize_interval,\n",
    "        disp=False,\n",
    "        niter_success=None,\n",
    "        seed=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "lPVkBFXeG-Mv"
   },
   "outputs": [],
   "source": [
    "def printClassInitArgs(class_obj):\n",
    "    print(f'{class_obj.name()}')\n",
    "    signature = inspect.signature(class_obj.__init__).parameters\n",
    "    print(\"-------------------------------\")\n",
    "    for name, parameter in signature.items():\n",
    "        if name != 'opposite':\n",
    "            print(\"Name: \", name, \"\\nDefault value:\", parameter.default)\n",
    "            #print(\"Annotation:\", parameter.annotation, \"\\nKind:\", parameter.kind)\n",
    "            print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQMoNUgSDTbj"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "#### Solve the following exercises, and answer these questions at the end:\n",
    "\n",
    "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "fbF-V__PHGPk",
    "outputId": "7c73f133-472b-473f-d318-8ee84dce14e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABC', 'Ackley', 'BenchmarkFunction', 'DeJong3', 'DeJong5', 'Easom', 'EggHolder', 'GoldsteinAndPrice', 'Griewank', 'Himmelblau', 'Hyperellipsoid', 'Hypersphere', 'Keane', 'MartinGaddy', 'McCormick', 'Michalewicz', 'PichenyGoldsteinAndPrice', 'PitsAndHoles', 'Rana', 'Rastrigin', 'Rosenbrock', 'Schaffer2', 'Schwefel', 'StyblinskiTang', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'abstractmethod', 'benchmark_functions', 'fil', 'functions_info_loader', 'logging', 'math', 'multivariate_normal', 'np']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'printClassInitArgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# BE AWARE: check the arguments each benchmark function takes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# if you're not sure, you can check the arguments by using the printClassInitArgs function\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(bf))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mprintClassInitArgs\u001b[49m(bf\u001b[38;5;241m.\u001b[39mHypersphere())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'printClassInitArgs' is not defined"
     ]
    }
   ],
   "source": [
    "# BE AWARE: check the arguments each benchmark function takes\n",
    "# if you're not sure, you can check the arguments by using the printClassInitArgs function\n",
    "print(dir(bf))\n",
    "printClassInitArgs(bf.Hypersphere())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mucSZghNDWCL"
   },
   "source": [
    "## Exercise 1/2: DIRECT\n",
    "In this first exercise we will use [DIRECT](https://scipydirect.readthedocs.io/en/latest/reference.html) as a search algorithm\n",
    "\n",
    "### Questions\n",
    "- How does the eps parameter influence the search process?\n",
    "\n",
    "A lower value of epsilon allows me to find a more accurate estimate of the function's minimum. The criterion for selecting the new rectangle is based on epsilon through the inequality: f(cj)-Kdj ≤ fmin - ε | fmin |. This implies that the difference between the function value at the central point of the new rectangle and the value of K multiplied by the rectangle's dimension must be less than the difference between the current minimum value and epsilon multiplied by the absolute value of the minimum. If this inequality is satisfied, then the new rectangle will be chosen for exploration.\n",
    "- How does the number of maximum iterations influence the search process? (To note: the maximum iterations and maximum number of evalutions are the soly metrics used to reach a stopping condition)\n",
    "\n",
    "Increasing the number of iterations leads to selecting more rectangles and dividing the search space into increasingly smaller regions. As the number of iterations increases, the algorithm tends to converge towards a local search. Simple functions may converge even with a low number of iterations, whereas complex functions require a higher number of iterations. If the minimum lies in the corners, the convergence becomes more challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1709841656248,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "cCKNQaaSDTma",
    "outputId": "c107162c-7370-45b7-fef2-250ff0808143"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.EggHolder())  # TODO: try differenct benchmark function\n",
    "eps = 0.1  # TODO: try different values\n",
    "max_iter = 300  # TODO: try different values\n",
    "max_eval = 100  # TODO try different values\n",
    "\n",
    "res, best_location, best_value = direct(func, eps, max_iter, max_eval)\n",
    "print(\"Best value:\", best_value)\n",
    "print(\"Best location:\", best_location)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kvWwb0tDbSZ"
   },
   "source": [
    "## Exercise 2/2: BASIN-HOPPING\n",
    "In this exercise we will use [Basin-hopping](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html) as a search algorithm\n",
    "\n",
    "### Questions\n",
    "- What is the influence of the following parameters on the search process?\n",
    "  - **T:** The “temperature” parameter for the acceptance or rejection criterion. Higher “temperatures” mean that larger jumps in function value will be accepted. For best results T should be comparable to the separation (in function value) between local minima;\n",
    "\n",
    "  La temperatura è una funzione decrescente in funzione del tempo e direttamente proporazionale alla probabilità di accettare il salto nel caso in cui il punto di arrivo è peggiore del punto in cui siamo. \n",
    "  - **stepsize:** Maximum step size for use in the random displacement;\n",
    "\n",
    "  Un valore maggiore di step size mi permette di fare salti più grandi e di conseguenza se abbiamo valli che sono molto lontane l'una dall'altra la probabilità di entrarci se abbiamo uno stepsize maggiore aumenta\n",
    "  - **stepsize_interval:** interval for how often to update the stepsize;\n",
    "\n",
    "\n",
    "  - **niter:** The number of basin-hopping iterations.\n",
    "\n",
    "  Un numero maggiore di niter mi permette di fare più salti e di conseguenza se niter tende ad infinito l'algoritmo tenderà a comportarsi come una random search\n",
    "- How does the number of maximum iterations influence the search process?\n",
    "\n",
    "\n",
    "- How does the starting point influence the search process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1709841656590,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "AD_oevi5DVJS",
    "outputId": "7d59e529-8bba-4f53-e8d6-7b39e000a7a7"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.EggHolder())  # TODO: try differenct benchmark functions\n",
    "x_0 = [-300, 200]  # set it appropriate for the funch used\n",
    "T = 10  # TODO: try different values\n",
    "stepsize = 0.1  # TODO: try different values\n",
    "stepsize_interval = 10  # TODO: try different values\n",
    "n_iter = 20  # TODO: try different values\n",
    "\n",
    "res = basinhopping(func, x_0, T, stepsize, stepsize_interval, n_iter)\n",
    "best_value, best_location = res['fun'], res['x']\n",
    "print(\"Best value:\", best_value)\n",
    "print(\"Best location:\", best_location)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lphxcGsFDjbT"
   },
   "source": [
    "## Final questions\n",
    "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1709841656590,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "XR0d_Yi8DkXy"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
