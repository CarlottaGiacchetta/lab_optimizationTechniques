{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU000j5BD2fA"
   },
   "source": [
    "## `Course evaluation information`\n",
    "\n",
    "- Concisely note down your observations for each lab from now on.\n",
    "- You can take notes inside the notebooks, or in separate PDFs.\n",
    "- Either way, be ready to show the work you putted into each lab, including the experiments and the learning outcomes.\n",
    "- During the exam, you will be asked to show your notes for some of the labs at random with a brief discussion on its content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjbcedKxD3_G"
   },
   "source": [
    "# Lab. 1: Local search\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### <u>The goal is to study the application of local search algorithms on different benchmark functions.</u>\n",
    "\n",
    "We will see the following methods:\n",
    "- *Grid Search*\n",
    "- *Random Search*\n",
    "- *Powell*\n",
    "- *Nelder Mead*\n",
    "\n",
    "Moreover, we will study how their parameters change the behavior of these algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "Getting started: the following code cell contains the core functions that we will use. Hence, **remember to run it every time the runtime is reconnected**.\n",
    "\n",
    "It contains the three local search algorithms and a wrapper class called *OptFun* for the benchmark function.\n",
    "As regards the *OptFun* class, the constructor takes as input a benchmark function (we will see later what functions are available). The relevant methods  are 4:\n",
    "1.   *Minima*: return the minimum of the function. The position can be obtained by the parameter *position* and the function value from the *score* parameter.\n",
    "2.   *Bounds*: returns where the function is defined\n",
    "3.   *Heatmap*: show a heatmap of the function highlighting the points visited by the local search (use with 2d function)\n",
    "4.   *plot*: show the trend of the points visited by the local search (use with 1d function)\n",
    "5.   *trend*: show the best points find during the optmization process.\n",
    "\n",
    "Each instance of *OptFun* stores the history of the point at which the function has been evaluated. The history is never cleaned and can be obtained through *OptFun.history*. Hence, if you reuse the class instance remember to clean the history (*OptFun.history = list()*).\n",
    "\n",
    "---\n",
    "\n",
    "The benchmark functions available comes from the *benchmark_functions* library (imported as *bf*).\n",
    "Example of the functions that can be used are the *Hypersphere*, the *Rastrign* the *DeJong5* and the Keane.\n",
    "The complete list of functions available can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions) or you can print it with *dir(bf)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8uoNBLJD5iC"
   },
   "source": [
    "#### Base code to run every time the runtime is reconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v31Sul4BDqx5"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "try:\n",
    "  import benchmark_functions as bf\n",
    "except:\n",
    "  !pip3 install benchmark_functions\n",
    "  import benchmark_functions as bf\n",
    "\n",
    "from scipy.optimize import minimize, rosen\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esjtvqg5D7FA"
   },
   "outputs": [],
   "source": [
    "class OptFun():\n",
    "    def __init__(self, wf):\n",
    "        self.f = wf\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, x0):\n",
    "        self.history.append(deepcopy(x0))\n",
    "        return self.f(x0)\n",
    "\n",
    "    def minima(self):\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounds(self):\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, fn = None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        fig.canvas.manager.set_window_title('Benchmark Function: '+self.f._name)\n",
    "        fig.suptitle(self.f._name)\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        if self.f._n_dimensions>1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray([[self.f((X[i][j],Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x,y,Z,15,linewidths=0.5,colors='k') # hight lines\n",
    "        plt.contourf(x,y,Z,15,cmap='viridis', vmin=Z.min(), vmax=Z.max()) # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history)>0:\t# plot points\n",
    "            xdata = [x[0] for x in self.history]\n",
    "            ydata = [x[1] for x in self.history]\n",
    "            plt.plot(xdata, ydata, \"or-\", markersize=2, linewidth=2)\n",
    "        if fn is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(fn, dpi=400)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        min = func.minima()[0].score\n",
    "        plt.plot(values)\n",
    "        plt.axhline(min, color=\"r\", label=\"optimum\")\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(self, bounds):\n",
    "        new_bounds= []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self):\n",
    "        return len(self.history)\n",
    "\n",
    "def grid_search(f: OptFun, step_size=None, number_of_steps=None):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the grid_search algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - step_size: the step size\n",
    "    - number_of_steps: the total number of steps\n",
    "    \"\"\"\n",
    "    bounds = f.bounds()\n",
    "    if (step_size != None):\n",
    "        for x in np.arange(bounds[0][0], bounds[0][1], step_size):\n",
    "            for y in np.arange(bounds[1][0], bounds[1][1], step_size):\n",
    "                func([x, y])\n",
    "    elif (number_of_steps != None):\n",
    "        for x in np.linspace(bounds[0][0], bounds[0][1], int(np.floor(np.sqrt(number_of_steps)))):\n",
    "            for y in np.linspace(bounds[1][0], bounds[1][1], int(np.floor(np.sqrt(number_of_steps)))):\n",
    "                func([x, y])\n",
    "    else:\n",
    "        print(\"Please provide at least the step_size or the\")\n",
    "\n",
    "def random_search(f: OptFun, n_samples_drawn):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the random_search algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - number_of_steps: the total number of steps\n",
    "    \"\"\"\n",
    "    bounds = f.bounds()\n",
    "    for i in range(n_samples_drawn):\n",
    "        x = np.random.uniform(bounds[0][0], bounds[0][1])\n",
    "        y = np.random.uniform(bounds[1][0], bounds[1][1])\n",
    "        func([x, y])\n",
    "\n",
    "def powell(f: OptFun, x0, maxiter: int):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the Powell algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - x0: starting point for the search process\n",
    "    - maxiter: maximum number of iterations\n",
    "    \"\"\"\n",
    "    bounds = f.bounds()\n",
    "    results = minimize(fun=f, x0=list(x0), method=\"powell\", bounds=bounds,\n",
    "                       options={\"ftol\":1e-4,\n",
    "                                \"maxfev\": None,\n",
    "                                \"maxiter\": maxiter,\n",
    "                                \"return_all\":True})\n",
    "    return results\n",
    "\n",
    "def nelder_mead(f: OptFun, x0, maxiter: int):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the Nelder-Mead algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - x0: starting point for the search process\n",
    "    - maxiter: maximum number of iterations\n",
    "    \"\"\"\n",
    "    bounds = f.bounds()\n",
    "    return minimize(\n",
    "        f,\n",
    "        x0,\n",
    "        method='Nelder-Mead',\n",
    "        tol=None,\n",
    "        bounds=bounds,\n",
    "        options={\n",
    "            \"maxfev\": None,\n",
    "            \"maxiter\": maxiter,\n",
    "            'disp': False,\n",
    "            'return_all': True,\n",
    "            'initial_simplex': None,\n",
    "            'xatol': 0.000,\n",
    "            'fatol': 0.000,\n",
    "            'adaptive': False\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-sBepeND-VN"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "#### Solve the following exercises, and answer these questions at the end:\n",
    "\n",
    "- How the benchmark functions influence the optimization algorithms? There is an algorithm which is always better than the other?\n",
    "- The choiche of the parameters is influenced by the function to optimize? And how the algorithms are influenced by the parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk1O3ORID_r1"
   },
   "source": [
    "## Exercise 1/4: GRID SEARCH\n",
    "In this first exercise we will use grid search as a search algorithm\n",
    "\n",
    "### Questions\n",
    "- How does the step size influence the quality of the best point obtained?\n",
    "- How does the step size influence the search cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "id": "HmWkhaFzD8HB",
    "outputId": "a10b3e46-671c-4113-b9e7-7ab25f9c6214"
   },
   "outputs": [],
   "source": [
    "hypersphere = bf.Hypersphere(2)  # TODO: try differenct benchmark functions\n",
    "func = OptFun(hypersphere)\n",
    "step_size = 1  # TODO: try different step_size values (e.g.: [0.5, 1, 3])\n",
    "\n",
    "grid_search(func, step_size=step_size)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rubg9cVGEEBm"
   },
   "source": [
    "## Exercise 2/4: RANDOM SEARCH\n",
    "\n",
    "In this exercise we will use Random Search to search for the optimum\n",
    "\n",
    "### Questions\n",
    "- How does the number of samples drawn affect the search?\n",
    "- How does this method compare to Grid Search? What are the advantages and disadvantages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "id": "GbBnfe1xECTk",
    "outputId": "0a3c4f96-9814-4b2c-bc26-4c8c4fc5547a"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.Hypersphere(2))  # TODO: try differenct benchmark functions\n",
    "bounds = func.bounds()\n",
    "n_samples_drawn = 30  # TODO: try different values (e.g.: [3, 30, 50])\n",
    "\n",
    "random_search(func, n_samples_drawn)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afqowvhaEFI_"
   },
   "outputs": [],
   "source": [
    "# TODO: compare to Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUAupSZJEIEA"
   },
   "source": [
    "## Exercise 3/4: POWELL OPTIMIZATION\n",
    "\n",
    "In this exercise we will focus on the Powel optimization algorithm.\n",
    "\n",
    "### Questions\n",
    "- What happens when varying the parameters of the algorithm?\n",
    "- How they influence the optimization process?\n",
    "- The effects of these parameters is the same across different functions?\n",
    "- How does this algorithm compare to the previous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQ8T_s0OEG3I",
    "outputId": "185e4a9a-fec0-47e8-a00e-c29f62171ca7"
   },
   "outputs": [],
   "source": [
    "# list of functions\n",
    "print(dir(bf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "id": "gO9gu3uiEJ2c",
    "outputId": "c642e427-9e29-46cd-bcda-e2a488453b14"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.Hypersphere(2))    # TODO: try differenct benchmark functions and parameters\n",
    "x_0 = [4.,-4.]  # TODO: try other suitable initial points\n",
    "max_iter = 1  # TODO: try other values\n",
    "\n",
    "powell(func, x_0, max_iter)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKMsWBW4EMop"
   },
   "source": [
    "## Exercise 4/4: NELDER MEAD OPTIMIZATION\n",
    "\n",
    "In this exercise we will focus on the Nelder Mead optimization algorithm.\n",
    "Similar to the previous exercise, answer the following questions:\n",
    "\n",
    "### Questions\n",
    "- What happens when varying the parameters of the algorithm?\n",
    "- How they influence the optimization process?\n",
    "- The effects of these parameters is the same across different functions?\n",
    "- How does this algorithm compare to the previous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "id": "0pXtC5qQEK3X",
    "outputId": "1f9d0d65-ab2b-4e32-9d2b-1a7a25c3a300"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.Hypersphere(2))  # TODO: try differenct benchmark functions and parameters\n",
    "x_0 = [-3.,4.]  # TODO: try other suitable initial points\n",
    "max_iter = 10  # TODO: try other values\n",
    "\n",
    "nelder_mead(func, x_0, max_iter)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBgMyrgREPo7"
   },
   "source": [
    "## Final questions\n",
    "- How the benchmark functions influence the optimization algorithms? There is an algorithm which is always better than the other?\n",
    "- The choiche of the parameters is influenced by the function to optimize? And how the algorithm are influenced by the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x67hRUq7ENoO"
   },
   "outputs": [],
   "source": [
    "# TODO: compare the different optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "L8uoNBLJD5iC",
    "Q-sBepeND-VN",
    "hk1O3ORID_r1",
    "Rubg9cVGEEBm",
    "KUAupSZJEIEA",
    "JKMsWBW4EMop"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
